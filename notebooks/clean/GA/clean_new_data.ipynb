{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from helper import clean_column_names\n",
    "\n",
    "from uid import gen_uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def standardize_key(df):\n",
    "#     df.loc[:, \"okey\"] = df.okey.str.lower().str.strip().str.replace(r\"\\s+\", \"\", regex=True)\n",
    "#     return df \n",
    "\n",
    "\n",
    "# def standardize_case(df):\n",
    "#     df.loc[:, \"case\"] = df.case.str.lower().str.strip().str.replace(r\"\\s+\", \"\", regex=True)\n",
    "#     return df \n",
    "\n",
    "\n",
    "\n",
    "# def read_history():\n",
    "#     df = pd.read_csv(\"../../../data/GA/2022-09-27/officer_employment-20231220144255.csv\")\n",
    "#     return df\n",
    "\n",
    "# df1 = read_history()\n",
    "\n",
    "# df1 = df1.pipe(clean_column_names).pipe(standardize_key)\n",
    "\n",
    "# def read_sanctions():\n",
    "#     df = pd.read_csv(\"../../../data/GA/2022-09-27/officer_sanctions-20231220144255.csv\")\n",
    "#     return df\n",
    "\n",
    "# df2 = read_sanctions()\n",
    "\n",
    "# df2 = df2.pipe(clean_column_names).pipe(standardize_case).pipe(standardize_key)\n",
    "\n",
    "# df2 = df2[[\"case\", \"sanction\"]]\n",
    "\n",
    "# def read_violations():\n",
    "#     df = pd.read_csv(\"../../../data/GA/2022-09-27/officer_violations-20231220144255.csv\")\n",
    "#     return df\n",
    "\n",
    "# df3 = read_violations()\n",
    "\n",
    "# df3 = df3.pipe(clean_column_names).pipe(standardize_case).pipe(standardize_key)\n",
    "\n",
    "# dfa = pd.merge(df2, df3, on=\"case\")\n",
    "\n",
    "# dfa = dfa[[\"okey\", \"case\", \"sanction\", \"violation\"]]\n",
    "\n",
    "\n",
    "# df = pd.merge(dfa, df1, on=\"okey\")\n",
    "\n",
    "# df.okey.nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "start_year\n",
       "7000        1\n",
       "2915        1\n",
       "2105        1\n",
       "2024     1949\n",
       "2023    16736\n",
       "2022    17012\n",
       "2021    16058\n",
       "2020    13561\n",
       "2019    17104\n",
       "2018    17278\n",
       "2017    16312\n",
       "2016    15247\n",
       "2015    16793\n",
       "2014    14452\n",
       "2013    15019\n",
       "2012    12989\n",
       "2011    10831\n",
       "2010    10207\n",
       "2009     9437\n",
       "2008    11036\n",
       "2007    12211\n",
       "2006    12723\n",
       "2005    11701\n",
       "2004    10477\n",
       "2003    10175\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def standardize_key(df):\n",
    "    df.loc[:, \"OKEY\"] = df.OKEY.str.lower().str.strip().str.replace(r\"\\s+\", \"\", regex=True)\n",
    "    return df \n",
    "\n",
    "def standardize_case(df):\n",
    "    df.loc[:, \"CASE\"] = df.CASE.str.lower().str.strip().str.replace(r\"\\s+\", \"\", regex=True)\n",
    "    return df \n",
    "\n",
    "\n",
    "def read_sanctions():\n",
    "    df = pd.read_csv(\"../../../data/GA/5-10-2024/officer_sanctions.csv\")\n",
    "    return df\n",
    "\n",
    "def read_violations():\n",
    "    df = pd.read_csv(\"../../../data/GA/5-10-2024/officer_violations.csv\")\n",
    "    return df\n",
    "\n",
    "def read_demo():\n",
    "    df = pd.read_csv(\"../../../data/GA/5-10-2024/officer_data.csv\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_history():\n",
    "    df = pd.read_csv(\"../../../data/GA/5-10-2024/officer_employment.csv\")\n",
    "    return df\n",
    "\n",
    "dfa = read_sanctions()\n",
    " \n",
    "dfa = dfa.pipe(standardize_key).pipe(standardize_case)\n",
    "\n",
    "dfb = read_violations()\n",
    "\n",
    "dfb = dfb.pipe(standardize_key).pipe(standardize_case)\n",
    "\n",
    "# dfb\n",
    "\n",
    "dfc = read_demo()\n",
    "\n",
    "dfc = dfc.pipe(standardize_key)\n",
    "\n",
    "\n",
    "dfd = read_history()\n",
    "\n",
    "dfd = dfd.pipe(standardize_key)\n",
    "\n",
    "\n",
    "def extract_year(df):\n",
    "    start_years = df[\"START DATE\"].str.extract(r\"^(\\w{4})\")\n",
    "\n",
    "    df.loc[:, \"start_year\"] = start_years[0]\n",
    "    return df \n",
    "\n",
    "\n",
    "\n",
    "dfd = dfd.pipe(extract_year)\n",
    "\n",
    "dfd.start_year.value_counts(ascending=True).sort_index(ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.merge(dfc, dfd, on=\"OKEY\")\n",
    "\n",
    "# df = df.pipe(clean_column_names)\n",
    "\n",
    "# df = df.rename(columns={\"yob\": \"birth_year\", \"okey\": \"uid\", \"middle\": \"middle_name\"})\n",
    "\n",
    "# df[\"state\"] = \"georgia\"\n",
    "\n",
    "\n",
    "# df.loc[:, \"hire_date\"] = df.start_date.str.replace(r\"(\\w{4})-(\\w{1,2})-(\\w{1,2})\", r\"\\2/\\3/\\1\", regex=True)\n",
    "# df.loc[:, \"left_date\"] = df.end_date.str.replace(r\"(\\w{4})-(\\w{1,2})-(\\w{1,2})\", r\"\\2/\\3/\\1\", regex=True)\n",
    "\n",
    "# df.loc[:, \"left_date\"] = df.left_date.str.replace(r\"(.+)\\/0000$\", \"\", regex=True)\n",
    "\n",
    "# df = df[~((df.left_date.fillna(\"\") == \"\"))]\n",
    "\n",
    "\n",
    "# events_df = df[[\"uid\", \"agency\", \"state\", \"hire_date\", \"left_date\"]]\n",
    "\n",
    "# # events_df.loc[:, \"left_date\"] = events_df.left_date.str.replace(r\"(.+)\\/0000$\", \"\", regex=True)\n",
    "\n",
    "# # events_df = events_df[~((events_df.left_date.fillna(\"\") == \"\"))]\n",
    "\n",
    "\n",
    "# # Unpivot the DataFrame\n",
    "# events_df = events_df.melt(id_vars=['uid', 'agency', 'state'], \n",
    "#                   value_vars=['hire_date', \"left_date\"], \n",
    "#                   var_name='event_type', \n",
    "#                   value_name='event_date')\n",
    "\n",
    "# events_df = events_df.pipe(gen_uid, ['uid', 'event_type', 'event_date'], \"event_uid\")\n",
    "\n",
    "\n",
    "# events_df\n",
    "# events_df.to_csv(\"events_ga_new.csv\", index=False)\n",
    "\n",
    "# df.loc[:, \"last_name\"] = df.last_name.str.lower()\n",
    "# df.loc[:, \"first_name\"] = df.first_name.str.lower()\n",
    "# df.loc[:, \"middle_name\"] = df.middle_name.str.lower()\n",
    "\n",
    "# df.loc[:, \"race\"] = (df\n",
    "#                      .race.str.lower()\n",
    "#                      .str.replace(r\"(.+)?black(.+)\", \"black\", regex=True)\n",
    "#                      .str.replace(r\"(.+)?white(.+)\", \"white\", regex=True)\n",
    "#                      .str.replace(r\"(.+)?asian(.+)\", \"asian\", regex=True)\n",
    "#                      .str.replace(r\"(.+)?indian(.+)\", \"american indian\", regex=True)\n",
    "#                         .str.replace(r\"(.+)?hawaiian(.+)\", \"pacific islander\", regex=True)\n",
    "#                      .str.replace(r\"^hispanic or latino\", \"hispanic\", regex=True)\n",
    "#                      .str.replace(r\"unknown\", \"\", regex=True)\n",
    "#                      .str.replace(r\"(.+)more(.+)\", \"mixed\", regex=True)\n",
    "# )\n",
    "\n",
    "# df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
